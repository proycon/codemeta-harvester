#!/bin/sh

# This tool harvests software metadata from source code repositories and makes it available as codemeta
#Files parsed: codemeta.json codemeta-harvest.json setup.py pyproject.toml pom.xml package.json README.md README.MD ReadMe.md readme.md README.rst README README.txt README.TXT CONTRIBUTORS AUTHORS MAINTAINERS CITATION.cff CITATION.CFF CITATION LICENSE LICENSE.md COPYING COPYRIGHT

VERSION="0.3.4" #also update in codemeta.json
SCRIPTDIR="$(realpath "$(dirname "$0")")"
DEBUG=0

#variants of README.md
README="README.md README.rst README README.txt README.TXT readme.txt README.MD ReadMe.md readme.md"

die() {
    DEBUG=1
    flushlog
    echo "[harvester fatal error] $*">&2
    [ -n "$LOGFILE" ] && echo "[harvester fatal error] $*" >> "$LOGFILE"
    exit 2
}

error() {
    OLDDEBUG=$DEBUG
    DEBUG=1
    flushlog
    DEBUG=$OLDDEBUG
    echo "[harvester error] $*">&2
    [ -n "$LOGFILE" ] && echo "[harvester error] $*" >> "$LOGFILE"
}

info() {
    echo "[harvester info] $*">&2
    [ -n "$LOGFILE" ] && echo "[harvester info] $*" >> "$LOGFILE"
}

debug() {
    if [ "$DEBUG" -gt 0 ]; then
        echo "[harvester debug] $*">&2
        [ -n "$LOGFILE" ] && echo "[harvester debug] $*" >> "$LOGFILE"
    fi
}

flushlog() {
    if [ "$DEBUG" -gt 0 ] && [ -e "$TMPLOG" ]; then
        echo "-- begin log --" >&2
        cat "$TMPLOG" >&2
        echo "-- end log --" >&2
        if [ -n "$LOGFILE" ]; then
            echo "-- begin log --" >> "$LOGFILE"
            cat "$TMPLOG" >> "$LOGFILE"
            echo "-- end log --" >> "$LOGFILE"
        fi
        rm "$TMPLOG"
    fi
}

usage() {
    echo "codemeta-harvester [--debug] [--ignore] [--regen] [--cachedir path] [--baseuri uri] [--outputdir path] [--opts codemetapy-options] [CONFIG_FILE_OR_DIRECTORY] ...">&2
    echo "   This tool harvests software metadata from source code repositories and makes it available as codemeta."
    echo "   If not file or directory is specified, the harvester will attempt to extract" >&2
    echo "   software metadata for the project in the current working directory and write a codemeta.json file there." >&2
    echo "">&2
    echo "Options:">&2
    echo "  --regen             Ignores reading the existing codemeta.json and regenerate it again (overwrites!)">&2
    echo "  --ignore            Ignores reading the existing codemeta.json">&2
    echo "  --baseuri [URI]     Sets the base URI to use for all RDF resources">&2
    echo "  --opts [ARGS]       Extra options to pass to codemetapy">&2
    echo "  --identifier [ARGS] Force this identifier (only works when not providing explicit input files)">&2
    echo "  --cachedir [PATH]   Directory to use for caching and storage of temporary files, all git repos will be cloned here">&2
    echo "  --debug             Output all logs"
    echo "  --keep              Keep intermediate output (in cachedir), don't clean up (useful for debugging)"
    echo "  --strict            Fail a conversion if one of it's main components fails"
    echo "  --stdout            Output to stdout (and don't keep output files)"
    echo "  --validate [file]   SHACL file to validate all metadata against"
    echo "  --validatetext      Header text for validation reports"
    echo "  --version           Output version"
}

missing=0
DEPENDENCIES="git sed python3 dasel codemetapy cffconvert recode awk"
for dependency in $DEPENDENCIES; do
    if ! command -v "$dependency" >/dev/null 2>/dev/null; then
        error "dependency $dependency not found" && missing=1
    fi
done
[ "$missing" -eq 1 ] && die "there are missing dependencies"

[ -n "$TMPDIR" ] || TMPDIR="/tmp"

CACHEDIR="$TMPDIR/codemeta-harvester.cache/"
KEEPCACHE=0
IGNORE=0
REGEN=0
CLEAN_README=0
STRICT=0
STDOUT=0
OUTPUTDIR=$(realpath .)
VALIDATE=
VALIDATETEXT=
CODEMETAPY_ARGS=""

while :; do
    case $1 in
        -h|--help)
            usage
            exit
            ;;
        -C|--cachedir)
            CACHEDIR=$2
            shift
            ;;
        -O|--outputdir)
            [ -n "$2" ] || die "Expected value for --outputdir"
            OUTPUTDIR="$(realpath "$2")"
            shift
            ;;
        -b|--baseuri)
            [ -n "$2" ] || die "Expected value for --baseurl"
            CODEMETAPY_ARGS="$CODEMETAPY_ARGS --baseuri $2"
            shift
            ;;
        --keep)
            KEEPCACHE=1
            ;;
        --ignore)
            IGNORE=1
            ;;
        --regen)
            REGEN=1
            IGNORE=1
            ;;
        --debug)
            DEBUG=1
            ;;
        --identifier)
            [ -n "$2" ] || die "Expected value for --identifier"
            IDENTIFIER="$2"
            shift
            ;;
        --strict)
            STRICT=1
            ;;
        --stdout)
            STDOUT=1
            if [ "$OUTPUTDIR" = "$(realpath .)" ]; then
                OUTPUTDIR=$TMPDIR
            fi
            ;;
        --opts)
            [ -n "$2" ] || die "Expected value for --opts"
            CODEMETAPY_ARGS="$CODEMETAPY_ARGS $2"
            shift
            ;;
        --validate)
            [ -n "$2" ] || die "Expected value for --validate"
            VALIDATE="$2"
            shift
            ;;
        --validatetext)
            [ -n "$2" ] || die "Expected value for --validatetext"
            VALIDATETEXT="$2"
            shift
            ;;
        -v|--version)
            echo $VERSION
            exit 0
            ;;
        -?*)
            die "Unknown option: $1"
            ;;
        *)
            [ -n "$1" ] && [ ! -e "$1" ] && die "Expected configuration file/directory, got invalid file/directory '$1'"
            break
    esac

    shift
done

info "codemeta-harvester $VERSION (outputdir=$OUTPUTDIR, cachedir=$CACHEDIR, opts=$CODEMETAPY_ARGS)"

TMPLOG="$CACHEDIR/codemeta-harvester.debug"

mkdir -p "$CACHEDIR" "$CACHEDIR/tmp" || die "Unable to create cache directory $CACHEDIR"

harvest() {
    # Harvest metadata from the current directory and convert it to codemeta
    ID="$1"
    REF="$2" #git ref
    CODEMETAPY_RECONCILE_ARGS="$3"
    if [ "$REF" != "master" ] && [ "$REF" != "main" ] && [ "$REF" != "develop" ] && [ "$REF" != "base" ]; then
        #assume we are on a release
        CODEMETAPY_RECONCILE_ARGS="$CODEMETAPY_RECONCILE_ARGS --released"
    fi
    SCANDIRS="$4 ."
    GROUP="$5"
    info "Git reference: $REF"
    #ensure there is nothing left from previous runs (might happen if one was run with --keep)
    rm -rf "$CACHEDIR/tmp/"*".$ID.codemeta.json"
    for scandir in $SCANDIRS; do
        oldcwd="$(pwd)"
        [ ! -d "$scandir" ] && continue
        info "Scanning directory $(realpath "$scandir") for harvestable resources..."
        cd "$scandir" || die "Unable to enter $scandir"

        CLEAN_README=0


        #First we grab all possible metadata and store it in the tmp dir
        if [ -e codemeta.json ] && [ $IGNORE -eq 0 ]; then
            #If there is an explicit codemeta.json, we will forego on all other detection methods
            #and assume it it the sole authoritative source for metadata.
            SUM=$(md5sum codemeta.json | cut -d " " -f 1)
            info "found codemeta.json for $ID (md5sum $SUM); **NOTE: this is considered authoritative and most other detection methods will be skipped now!**"
            #basic sanity check to see if the codemeta is well-formed (=no syntax errors)
            if dasel -n -f codemeta.json > /dev/null; then
                cp codemeta.json "$CACHEDIR/tmp/10-jsonld.$ID.codemeta.json"
                #                               ^-- lowest number indicates highest priority
            else
                error "codemeta.json for $ID is not well-formed"
                [ $STRICT -eq 1 ] && return 1
            fi
            [ -e codemeta-harvest.json ] && info "Your codemeta-harvest.json is ignored because you already have a codemeta.json!"
            if [ -e CITATION.CFF ] || [ -e CITATION.cff ] || [ -e CITATION ]; then
                info "Your CITATION.cff is ignored because you already have a codemeta.json!"
            fi
        else
            #No codemeta found, automatically extract from other sources.
            #(This allows for recombining from multiple sources)

            #If there is a codemeta-harvest.json, we will add it to
            #any other existing metadata that can be found
            cd "$scandir" || die "Unable to enter $scandir"
            if [ -e codemeta-harvest.json ]; then
                SUM=$(md5sum codemeta-harvest.json | cut -d " " -f 1)
                info "found codemeta-harvest.json for $ID (md5sum $SUM); values in here take precendence over (override) those in later detection stages"
                #basic sanity check to see if the codemeta is well-formed (=no syntax errors)
                if dasel -n -f codemeta-harvest.json > /dev/null; then
                    cp codemeta-harvest.json "$CACHEDIR/tmp/10-harvest.$ID.codemeta.json"
                    #                               ^-- lowest number indicates highest priority
                else
                    error "codemeta-harvest.json for $ID is not well-formed"
                    [ $STRICT -eq 1 ] && return 1
                fi
            fi

            cd "$scandir" || die "Unable to enter $scandir"
            for f in CITATION.cff CITATION.CFF CITATION; do
                if [ -e "$f" ]; then
                    info "found CITATION.cff for $ID, converting to codemeta"
                    if ! cffconvert -i "$f" -o "$CACHEDIR/tmp/12-citationcff.$ID.codemeta.json" -f codemeta 2> "$TMPLOG" >&2; then
                        error "CITATION.cff to codemeta conversion for $ID failed"
                        [ $STRICT -eq 1 ] && return 1
                    fi
                    flushlog
                    break
                fi
            done

            cd "$scandir" || die "Unable to enter $scandir"
            if [ -e setup.py ] || [ -e pyproject.toml ]; then
                info "found python setup for $ID, converting to codemeta"
                #shellcheck disable=SC2086 #(allow globbing and splitting for $CODEMETAPY_ARGS)
                if ! codemetapy $CODEMETAPY_ARGS -O "$CACHEDIR/tmp/20-python.$ID.codemeta.json" 2> "$TMPLOG" >&2; then
                    error "python setup.py to codemeta conversion failed for $ID (codemetapy failed)"
                    [ $STRICT -eq 1 ] && return 1
                fi
                flushlog
            fi

            cd "$scandir" || die "Unable to enter $scandir"
            if [ -e pom.xml ]; then
                info "found pom.xml (Java/Maven) for $ID, converting to codemeta"
                #shellcheck disable=SC2086 #(allow globbing and splitting for $CODEMETAPY_ARGS)
                if ! codemetapy $CODEMETAPY_ARGS -O "$CACHEDIR/tmp/21-java.$ID.codemeta.json" pom.xml 2> "$TMPLOG" >&2; then
                    error "pom.xml to codemeta conversion failed for $ID (codemetapy failed)"
                    [ $STRICT -eq 1 ] && return 1
                fi
                flushlog
            fi

            cd "$scandir" || die "Unable to enter $scandir"
            if [ -e package.json ]; then
                info "found package.json (NodeJS) for $ID, converting to codemeta"
                #shellcheck disable=SC2086 #(allow globbing and splitting for $CODEMETAPY_ARGS)
                if ! codemetapy $CODEMETAPY_ARGS -O "$CACHEDIR/tmp/22-npm.$ID.codemeta.json" package.json 2> "$TMPLOG" >&2; then
                    error "package.json to codemeta conversion failed for $ID (codemetapy failed)"
                    [ $STRICT -eq 1 ] && return 1
                fi
                flushlog
            fi


            cd "$scandir" || die "Unable to enter $scandir"
            [ -e "$SCRIPTDIR/detect-license.sh" ] || die "Unable to find detect-license.sh in $SCRIPTDIR"
            info "Looking for license...."
            SPDX=$("$SCRIPTDIR/detect-license.sh" 2> "$TMPLOG")
            if [ -n "$SPDX" ]; then
                info "Found license $SPDX"
                echo "{ \"license\": \"$SPDX\" }" > "$CACHEDIR/tmp/29-license.$ID.codemeta.json"
            else
                info "No license file found"
            fi
            flushlog

            cd "$scandir" || die "Unable to enter $scandir"
            if [ -f MAINTAINERS ]; then
                info "Parsing MAINTAINERS..."
                #shellcheck disable=SC2086 #(allow globbing and splitting for $CODEMETAPY_ARGS)
                if ! codemetapy $CODEMETAPY_ARGS -O "$CACHEDIR/tmp/30-maintainers.$ID.codemeta.json" -i maintainers "MAINTAINERS" 2> "$TMPLOG" >&2; then
                    error "Parsing MAINTAINERS file failed for $ID (codemetapy failed)"
                fi
                flushlog
            fi

            cd "$scandir" || die "Unable to enter $scandir"
            if [ -f AUTHORS ]; then
                info "Parsing AUTHORS..."
                #shellcheck disable=SC2086 #(allow globbing and splitting for $CODEMETAPY_ARGS)
                if ! codemetapy $CODEMETAPY_ARGS -O "$CACHEDIR/tmp/31-authors.$ID.codemeta.json" -i authors "AUTHORS" 2> "$TMPLOG" >&2; then
                    error "Parsing AUTHORS file failed for $ID (codemetapy failed)"
                fi
                flushlog
            fi

            cd "$scandir" || die "Unable to enter $scandir"
            if [ -f CONTRIBUTORS ]; then
                info "Parsing CONTRIBUTORS..."
                #shellcheck disable=SC2086 #(allow globbing and splitting for $CODEMETAPY_ARGS)
                if ! codemetapy $CODEMETAPY_ARGS -O "$CACHEDIR/tmp/32-contributors.$ID.codemeta.json" -i contributors "CONTRIBUTORS" 2> "$TMPLOG" >&2; then
                    error "Parsing CONTRIBUTORS file failed for $ID (codemetapy failed)"
                fi
            else
                info "Getting contributors from git..."
                #Get all authors from git (in order of nr of commits)
                if ! git log --pretty=short | git shortlog -s -e | grep -Fv "@noreply" | grep -v "snyk-bot" | grep -v "dependabot" | grep -v "badger@gitter.im" | grep -v dependabot | sort -rn | cut -f 2 > "$CACHEDIR/tmp/$ID.CONTRIBUTORS"; then
                    error "git shortlog failed"
                fi
                if [ -s "$CACHEDIR/tmp/$ID.CONTRIBUTORS" ]; then
                    #shellcheck disable=SC2086 #(allow globbing and splitting for $CODEMETAPY_ARGS)
                    if ! codemetapy $CODEMETAPY_ARGS -O "$CACHEDIR/tmp/32-contributors.$ID.codemeta.json" -i contributors "$CACHEDIR/tmp/$ID.CONTRIBUTORS" 2> "$TMPLOG" >&2; then
                        error "Parsing contributors failed for $ID (codemetapy failed)"
                    fi
                else
                    info "No git contributors found"
                fi
            fi
            flushlog

            cd "$scandir" || die "Unable to enter $scandir"
            info "Extracting last and first commit date from git log...."
            #alternative: git shortlog --format=format:%cI | grep -vF '(' | sed 's/[[:space:]]//g' |  awk NF | tail -n 1 OR head -1
            DATE_UPDATED=$(git log -1 --date=format:"%Y-%m-%dT%TZ%z" --format="%ad")
            DATE_CREATED=$(git log --date=format:"%Y-%m-%dT%TZ%z" --format="%ad" | tail -n 1)
            if [ -n "$DATE_UPDATED" ] && [ -n "$DATE_CREATED" ]; then
                echo "{ \"dateCreated\": \"$DATE_CREATED\", \"dateModified\": \"$DATE_UPDATED\" }" > "$CACHEDIR/tmp/39-gitdate.$ID.codemeta.json"
                info "Date created: $DATE_CREATED, date modified: $DATE_UPDATED"
            fi

            GIT_REMOTE_URL=$(git remote get-url origin | sed 's|git@|https://|' | sed "s|:([A-Za-z])|/\1|" | sed "s|\.git$||")
            #                                                                          ^-- github.com:proycon -> github.com/proycon (but ensure we don't mismatch on host:port)
            case "$GIT_REMOTE_URL" in 
                *bitbucket*|*git.sr.ht*|*codeberg.org)
                    info "Not querying API for $GIT_REMOTE_URL (no implementation)"
                    ;;
                *)
                    info "Querying Github/GitLab API ($GIT_REMOTE_URL)"
                    #shellcheck disable=SC2086 #(allow globbing and splitting for $CODEMETAPY_ARGS)
                    if ! codemetapy $CODEMETAPY_ARGS -O "$CACHEDIR/tmp/40-gitapi.$ID.codemeta.json" -i gitapi "$GIT_REMOTE_URL" 2> "$TMPLOG" >&2; then
                        error "conversion from Github/GitLab API query failed for $ID ($GIT_REMOTE_URL) (codemetapy failed)"
                    fi
                    flushlog
                    ;;
            esac

            #Add README URL
            cd "$scandir" || die "Unable to enter $scandir"
            for f in $README; do
                if [ -e "$f" ]; then
                    info "Found $f"
                    echo " { \"readme\": \"$GIT_REMOTE_URL/blob/$REF/$f\" }"  > "$CACHEDIR/tmp/41-readme.$ID.codemeta.json"
                    break
                fi
            done

            #Add build instructions URL
            cd "$scandir" || die "Unable to enter $scandir"
            for f in INSTALL.md INSTALL.rst INSTALL BUILD.md BUILD.rst BUILD INSTALL.MD; do
                if [ -e "$f" ]; then
                    info "Found buildInstructions in $f"
                    echo " { \"buildInstructions\": \"$GIT_REMOTE_URL/blob/$REF/$f\" }"  > "$CACHEDIR/tmp/42-buildinstructions.$ID.codemeta.json"
                    break
                fi
            done

            #Add release notes URL and download URL
            if [ -n "$REF" ] && [ "$REF" != "master" ] && [ "$REF" != "main" ]; then
                info "Found releaseNotes"
                echo " { \"releaseNotes\": \"$GIT_REMOTE_URL/releases/tag/$REF\", \"downloadUrl\": \"$GIT_REMOTE_URL/archive/refs/tags/$REF.zip\" }"  > "$CACHEDIR/tmp/43-releasenotes.$ID.codemeta.json"
            fi
            #fi

            ##Query DOI via Zenodo API, retrieves the DOI specific to this version
            if [ -n "$REF" ] && [ "$REF" != "master" ] && [ "$REF" != "main" ]; then
                if [ -n "$ZENODO_ACCESS_TOKEN" ]; then
                    info "Querying Zenodo API for DOI (access token provided)..."
                    Q="?access_token=$ZENODO_ACCESS_TOKEN&"
                else
                    info "Querying Zenodo API for DOI (no access token provided)..."
                    Q="?"
                fi
                DOI=$(curl "https://zenodo.org/api/records/${Q}q=related.identifier:\"$GIT_REMOTE_URL/tree/$REF\"" | dasel -p json -s ".hits.hits.[0].links.doi" | tr -d '"')
                if [ -n "$DOI" ]; then
                    info "Found DOI $DOI"
                    #takes precendence over codemeta.json (because it's impossible to include a codemeta.json with a DOI in a version tagged repo)
                    echo "{ \"identifier\": [ \"$IDENTIFIER\", { \"@type\": \"PropertyValue\",\"propertyID\":\"doi\", \"value\": \"$DOI\" } ] }"  > "$CACHEDIR/tmp/05-doi.$ID.codemeta.json" 
                fi
            fi

            cd "$scandir" || die "Unable to enter $scandir"
            if [ -e README.rst ] && [ ! -e README.md ]; then
                info "Converting README.rst to README.md"
                pandoc README.rst --to gfm -o README.md
                CLEAN_README=1
            fi

            cd "$scandir" || die "Unable to enter $scandir"
            for f in $README; do
                if [ -e "$f" ]; then

                    #Detect TRL via badges
                    info "Looking for TRL information in $f..."
                    TRL=$("$SCRIPTDIR/detect-trl.sh" < "$f" 2> "$TMPLOG" | head -n 1)
                    if [ -z "$TRL" ]; then
                        #Infer TRL via stability marker (https://masterminds.github.io/stability/)
                        #note: this may also return a repostatus if more appropriate
                        TRL=$("$SCRIPTDIR/detect-trl-from-stability.sh" < "$f" 2> "$TMPLOG" | head -n 1)
                    fi
                    if [ -n "$TRL" ]; then
                        info "Found TRL $TRL"
                        echo "{ \"developmentStatus\": \"$TRL\" }" > "$CACHEDIR/tmp/11-trl.$ID.codemeta.json"
                    elif [ "$REPOSTATUS" = "https://www.repostatus.org/#concept" ]; then
                        info "Mapping repostatus $REPOSTATUS to trl:Stage2Concept"
                        echo "{ \"developmentStatus\": \"https://w3id.org/research-technology-readiness-levels#Stage2Concept\" }" > "$CACHEDIR/tmp/11-trl.$ID.codemeta.json"
                    elif [ "$REPOSTATUS" = "https://www.repostatus.org/#wip" ]; then
                        info "Mapping repostatus $REPOSTATUS to trl:Stage3Experimental"
                        echo "{ \"developmentStatus\": \"https://w3id.org/research-technology-readiness-levels#Stage3Experimental\" }" > "$CACHEDIR/tmp/11-trl.$ID.codemeta.json"
                    fi
                    flushlog

                    #Detect developmentStatus via repostatus badges
                    info "Looking for repostatus information in $f..."
                    REPOSTATUS=$("$SCRIPTDIR/detect-repostatus.sh" < "$f" 2> "$TMPLOG" | head -n 1)
                    if [ -n "$REPOSTATUS" ]; then
                        info "Found repostatus $REPOSTATUS"
                        echo "{ \"developmentStatus\": \"$REPOSTATUS\" }" > "$CACHEDIR/tmp/11-repostatus.$ID.codemeta.json"
                    fi
                    flushlog

                    #Detect contIntegration 
                    info "Looking for continuous integration information in $f..."
                    CI=$("$SCRIPTDIR/detect-ci.sh" < "$f" 2> "$TMPLOG" | head -n 1)
                    if [ -n "$CI" ]; then
                        info "Found CI $CI"
                        echo "{ \"contIntegration\": \"$CI\" }" > "$CACHEDIR/tmp/12-ci.$ID.codemeta.json"
                    fi
                    flushlog


                    #Detect links to documentation
                    info "Looking for documentation links in $f..."
                    URLS=$("$SCRIPTDIR/detect-documentation.sh" < "$f" 2> "$TMPLOG")
                    if [ -n "$URLS" ]; then
                        echo "{ \"softwareHelp\": [" > "$CACHEDIR/tmp/50-documentation.$ID.codemeta.json"
                        COUNT=0
                        for URL in $URLS; do
                            TITLE=$(scrape_html_title "$URL")
                            [ -n "$TITLE" ] && TITLE="\"name\": \"$TITLE\","
                            info "Found documentation at $URL : $TITLE"
                            [ $COUNT -gt 0 ] && echo "," >>  "$CACHEDIR/tmp/50-documentation.$ID.codemeta.json"
                            echo "{ \"@id\": \"$URL\", $TITLE \"@type\": \"WebSite\", \"url\": \"$URL\" }" >>  "$CACHEDIR/tmp/50-documentation.$ID.codemeta.json"
                            COUNT=$((COUNT+1))
                        done
                        echo "]}" >> "$CACHEDIR/tmp/50-documentation.$ID.codemeta.json"
                    fi
                    flushlog
                    break
                fi
            done

            #somef is optional because it relies on many dependencies that not everybody may want:
            cd "$scandir" || die "Unable to enter $scandir"
            if command -v somef 2> /dev/null >&2; then
                for f in $README; do
                    if [ -e "$f" ]; then
                        info "Analyzing README..."
                        if ! somef describe -c "$CACHEDIR/tmp/40-somef.$ID.codemeta.json" -d "$f" 2> "$TMPLOG" >&2; then
                            error "README to codemeta conversion failed for $ID"
                        fi
                        flushlog
                        break
                    fi
                done
            fi

            if [ -n "$REF" ] && [ "$REF" != "master" ] && [ "$REF" != "main" ]; then
                #in case no version number can be found anywhere, we fall back to the git tag
                info "Falling back to git tag ($REF) if no version number is specified..."
                echo "{ \"version\": \"$REF\" }" > "$CACHEDIR/tmp/99-version.$ID.codemeta.json"
            fi
            #remove the readme again if it comes from our conversion
            [ $CLEAN_README -eq 1 ] && rm README.md


            cd "$oldcwd" || die "Unable to return to $oldcwd"
        fi

        if [ -n "$REF" ] && [ "$REF" != "master" ] && [ "$REF" != "main" ]; then
            #some properties we prefer to take from the very latest master branch
            #and backport to older versions (such as maintainer and repostatus)
            #because these are more repo-bound than version bound...

            #we do this even if an explicit codemeta.json was provided!

            CURRENT_BRANCH=$(git rev-parse --abbrev-ref HEAD)
            DEFAULT_BRANCH=$(git_default_branch)
            oldcwd="$(pwd)"
            cd "$scandir" || die "Unable to enter $scandir"
            if ! git checkout "$DEFAULT_BRANCH" 2> "$TMPLOG"; then
                #fallback, stash and retry:
                git stash -u 2>> "$TMPLOG"
                git checkout "$DEFAULT_BRANCH" 2>> "$TMPLOG" || die "Unable to checkout default git branch $DEFAULT_BRANCH"
            fi
        else
            CURRENT_BRANCH=
        fi

        info "Inferring repostatus information from git activity (used only as a fallback if not explicitly provided)..."
        DETECTED_VERSION=
        for f in $(find "$CACHEDIR/tmp/" -maxdepth 1 -name "*.$ID.codemeta.json" | sort); do
            DETECTED_VERSION=$(dasel -f "$f" -s .version 2> /dev/null | tr -d '"')
            [ -n "$DETECTED_VERSION" ] && break
        done
        REPOSTATUS=$("$SCRIPTDIR/detect-repostatus-from-git.sh" "$DETECTED_VERSION" 2> "$TMPLOG" | head -n 1)
        if [ -n "$REPOSTATUS" ]; then
            info "Inferred repostatus $REPOSTATUS"
            echo "{ \"developmentStatus\": \"$REPOSTATUS\" }" > "$CACHEDIR/tmp/99-repostatus.$ID.codemeta.json"
        fi

        if [ -n "$REF" ] && [ "$REF" != "master" ] && [ "$REF" != "main" ]; then
            for f in $README; do
                if [ -e "$f" ]; then
                    #Detect developmentStatus via repostatus badges
                    info "Looking for repostatus information in $f in master branch..."
                    REPOSTATUS=$("$SCRIPTDIR/detect-repostatus.sh" < "$f" 2> "$TMPLOG" | head -n 1)
                    if [ -n "$REPOSTATUS" ]; then
                        info "Found repostatus (master branch) $REPOSTATUS"
                        echo "{ \"developmentStatus\": \"$REPOSTATUS\" }" > "$CACHEDIR/tmp/05-repostatus.$ID.codemeta.json" #this overwrite the version-specific one and takes precendence even over codemeta.json!
                    fi
                    flushlog
                fi
            done

            if [ -f MAINTAINERS ]; then
                #takes precendence even over codemeta.json!
                info "Parsing MAINTAINERS from master branch..."
                #shellcheck disable=SC2086 #(allow globbing and splitting for $CODEMETAPY_ARGS)
                if ! codemetapy $CODEMETAPY_ARGS -O "$CACHEDIR/tmp/05-maintainers.$ID.codemeta.json" -i maintainers "MAINTAINERS" 2> "$TMPLOG" >&2; then
                    error "Parsing MAINTAINERS file failed for $ID (codemetapy failed)"
                fi
                flushlog
            fi
        fi

        if [ -n "$GROUP" ]; then
            #groups assigned in the harvester configuration always take precendence, even over codemeta.json
            info "Setting group $GROUP"
            echo "{ \"applicationSuite\": \"$GROUP\" }" > "$CACHEDIR/tmp/04-applicationSuite.$ID.codemeta.json"
        fi

        if [ -n "$CURRENT_BRANCH" ]; then
            if ! git checkout "$CURRENT_BRANCH" 2> "$TMPLOG"; then
                #fallback, stash and retry
                git stash -u 2>> "$TMPLOG"
                git checkout "$CURRENT_BRANCH" || die "Unable to switch to previous git branch"
            fi
            cd "$oldcwd" || die "Unable to return to $oldcwd"
        fi
    done

    files=$(ls -r "$CACHEDIR"/tmp/*."$ID".codemeta.json | tr "\n" " ")

    if [ -z "$files" ]; then
        error "No metadata sources found for $ID"
        return 1
    fi

    RESCAN=0
    for f in $files; do
        if ! dasel -f "$f" -p json > /dev/null; then
            error "File $f is not valid JSON, removing..."
            rm "$f"
            RESCAN=1
        fi
    done

    [ $RESCAN -eq 1 ] && files=$(ls -r "$CACHEDIR"/tmp/*."$ID".codemeta.json | tr "\n" " ")

    #Last we reconciliate all metadata using codemetapy
    #this is done in increasing order of priority, where higher priority items (lower number) replace earlier lower priority ones
    OUT_ARG="-O $OUTPUTDIR/$ID.codemeta.json"
    info "Reconciliating: codemetapy $CODEMETAPY_ARGS $CODEMETAPY_RECONCILE_ARGS --enrich --textv \"$VALIDATETEXT\" $OUT_ARG $files"
    #shellcheck disable=SC2086 #(allow globbing and splitting for $CODEMETAPY_*ARGS)
    if ! codemetapy $CODEMETAPY_ARGS $CODEMETAPY_RECONCILE_ARGS --enrich --textv "$VALIDATETEXT" $OUT_ARG $files 2> "$TMPLOG" >&2; then
        error "Failed to consolidate metadata $ID"
        [ $STDOUT -eq 0 ] && rm "$OUTPUTDIR/$ID.codemeta.json" 2>/dev/null #clean up possible partial output
        return 1
    else
        OLD_DEBUG=$DEBUG
        DEBUG=1 #force log output for reconciliation step
        flushlog
        DEBUG=$OLD_DEBUG
        [ $STDOUT -eq 0 ] && info "Output written to $OUTPUTDIR/$ID.codemeta.json"
    fi
    [ $KEEPCACHE -eq 0 ] && rm -rf "$CACHEDIR/tmp/"*".$ID.codemeta.json"
}

harvest_service() {
    # Harvest metadata from a remote service endpoint and add it to the codemeta representation via
    # the "targetProduct" property and one of the software types (https://github.com/codemeta/codemeta/issues/271)
    ID="$1"
    URL="$2"
    info "Harvesting remote service URL $URL for $ID: codemetapy $CODEMETAPY_ARGS -O \"$CACHEDIR/tmp/$ID.codemeta.json\" \"$OUTPUTDIR/$ID.codemeta.json\" \"$URL\""
    #shellcheck disable=SC2086 #(allow globbing and splitting for $CODEMETAPY_ARGS)
    if codemetapy $CODEMETAPY_ARGS -O "$CACHEDIR/tmp/$ID.codemeta.json" "$OUTPUTDIR/$ID.codemeta.json" "$URL" 2> "$TMPLOG" >&2; then
        flushlog
        mv -f "$CACHEDIR/tmp/$ID.codemeta.json" "$OUTPUTDIR/$ID.codemeta.json"
    else
        error "Failed to obtain or process metadata from remote service URL $URL for $ID"
        return 1
    fi
}


get_latest_version() {
    #Finds the latest git tag or falls back to returning the git default branch (usually master or main)
    #Assumes some kind of semantic versioning (possibly with a v prefix), also allows a one-letter suffix
    #does not allow suffixes like -rc1  and -alpha (those are seen as pre-releases rather than full releases)
    TAG=$(git tag --sort version:refname | grep -E "^${TAGPREFIX}v?[0-9]+(\.[0-9])*[A-Za-z]?" | tail -n 1)
    if [ -z "$TAG" ]; then
        info "No releases found, falling back to default git branch!"
        git_default_branch
    else
        info "Found release $TAG"
        echo "$TAG"
    fi
}

git_default_branch() {
    #output the git default branch for the repository in the current working dir (usually master or main)
    git symbolic-ref refs/remotes/origin/HEAD | sed 's@^refs/remotes/origin/@@'
}

scrape_html_title() {
    #Scrape the title from a webpage
    info "Scraping title from $1"
    curl -s -L "$1" | gawk 'BEGIN{IGNORECASE=1;FS="<title>|</title>";RS=EOF} {print $2}' | sed '/^$/d' | recode html..utf8 | sed "s/\"/'/g"
}

process() {
    #read a configuration file and harvest the source
    cd "$WORKDIR" || die "Unable to enter $WORKDIR"
    CONFIGFILE="$1"
    ID=$(basename "$CONFIGFILE" | sed -e 's/\.yaml//' -e 's/\.yml//')
    SOURCEREPO=$(dasel --null -r yaml ".source" < "$CONFIGFILE")
    ROOTPATH=$(dasel --null -r yaml ".root" < "$CONFIGFILE")
    SCANDIRS=$(dasel --null -r yaml --plain ".scandirs" < "$CONFIGFILE" | tr -d "[]")
    SERVICE_URLS=$(dasel --null -r yaml --plain ".services" < "$CONFIGFILE" | tr -d "[]")
    GROUP=$(dasel --null -r yaml --plain ".group" < "$CONFIGFILE" | tr -d "[]")
    TAGPREFIX=$(dasel --null -r yaml --plain ".tagprefix" < "$CONFIGFILE" | tr -d "[]")
    [ "$GROUP" = "null" ] && GROUP=
    [ "$TAGPREFIX" = "null" ] && TAGPREFIX=
    #Get the requested ref (branch or tag or commit) from the config (if present, otherwise the latest tag will be extracted automatically)
    REF=$(dasel --null -r yaml ".ref" < "$CONFIGFILE")
    LOGFILE="$OUTPUTDIR/$ID.harvest.log"
    echo "(log file starts at $(date))" > "$LOGFILE"
    if [ -z "$SOURCEREPO" ] || [ "$SOURCEREPO" = "null" ]; then
        #no source repo defined: service is an 'orphan'
        [ -n "$SERVICE_URLS" ] || die "invalid configuration: $ID"
        info "--> Processing orphan service $ID [$(date)]"
        CODEMETAPY_RECONCILE_ARGS="--identifier \"$ID\""
        [ -n "$VALIDATE" ] && CODEMETAPY_RECONCILE_ARGS="$CODEMETAPY_RECONCILE_ARGS --validate $VALIDATE"
        #create a dummy SoftwareSourceCode entry (with no actual codeRepository)
        info "Creating dummy codemeta.json for orphan service: codemetapy $CODEMETAPY_RECONCILE_ARGS /dev/null > $OUTPUTDIR/$ID.codemeta.json"
        codemetapy $CODEMETAPY_RECONCILE_ARGS /dev/null > "$OUTPUTDIR/$ID.codemeta.json" 2> "$TMPLOG" || error "Failed to create dummy codemeta.json for $ID"
    else
        #normal behaviour: source repo defined
        info "--> Processing $ID ($SOURCEREPO) [$(date)]"
        CODEMETAPY_RECONCILE_ARGS="--identifier \"$ID\" --codeRepository \"$SOURCEREPO\""
        [ -n "$VALIDATE" ] && CODEMETAPY_RECONCILE_ARGS="$CODEMETAPY_RECONCILE_ARGS --validate $VALIDATE"
        if [ -d "$CACHEDIR/$ID" ]; then
            cd "$CACHEDIR/$ID" || die "failed to enter directory $CACHEDIR/$ID"
            info "Git updating cached clone of $SOURCEREPO..."
            if git fetch origin --tags 2> "$TMPLOG" >&2; then
                if [ -z "$REF" ] || [ "$REF" = "null" ]; then
                    REF=$(get_latest_version)
                fi
                info "Using $REF"
                if ! git -c advice.detachedHead=false checkout -f "$REF" 2> "$TMPLOG" >&2; then
                    git stash -u 2>> "$TMPLOG"
                    git -c advice.detachedHead=false checkout -f "$REF" 2>> "$TMPLOG" || die "Invalid git ref '$REF' or unclean working dir"
                fi
                #pull may still be needed to fast-forward local branch
                if ! git pull origin $REF; then
                    error "Failed to pull $SOURCEREPO"
                    unset -v LOGFILE
                    exit 1
                fi
                if [ -n "$ROOTPATH" ] && [ "$ROOTPATH" != "null" ]; then
                    cd "$ROOTPATH" || die "Unable to enter $ROOTPATH"
                fi
                harvest "$ID" "$REF" "$CODEMETAPY_RECONCILE_ARGS" "$SCANDIRS" "$GROUP"
            else
                error "Failed to git pull $SOURCEREPO"
                unset -v LOGFILE
                return 1
            fi
        else
            cd "$CACHEDIR" || die "failed to enter cache directory $CACHEDIR"
            info "Git light cloning $SOURCEREPO..."
            if git clone --filter=blob:limit=999k "$SOURCEREPO" "$CACHEDIR/$ID" 2> "$TMPLOG" >&2; then
                cd "$CACHEDIR/$ID" || die "failed to enter dir $CACHEDIR/$ID"
                if [ -z "$REF" ] || [ "$REF" = "null" ]; then
                    REF=$(get_latest_version)
                fi
                info "Using $REF for $ID"
                if ! git -c advice.detachedHead=false checkout -f "$REF" 2> "$TMPLOG" >&2; then
                    git stash -u 2>> "$TMPLOG"
                    git -c advice.detachedHead=false checkout -f "$REF" 2>> "$TMPLOG" || die "Invalid git ref '$REF' or unclean working dir"
                fi
                if [ -n "$ROOTPATH" ]  && [ "$ROOTPATH" != "null" ]; then
                    cd "$ROOTPATH" || die "Unable to enter $ROOTPATH"
                fi
                harvest "$ID" "$REF" "$CODEMETAPY_RECONCILE_ARGS" "$SCANDIRS" "$GROUP"
            else
                error "Failed to git clone $SOURCEREPO"
                unset -v LOGFILE
                return 1
            fi
        fi
    fi

    #Process services
    if [ -n "$SERVICE_URLS" ] && [ "$SERVICE_URLS" != "null" ]; then
        for URL in $SERVICE_URLS; do
            harvest_service "$ID" "$URL"
        done
    fi

    info "<-- Finished processing $ID ($SOURCEREPO) [$(date)]"
    unset -v LOGFILE
    if [ $STDOUT -eq 0 ]; then
        info "Log written to $OUTPUTDIR/$ID.harvest.log"
    else
        cat "$OUTPUTDIR/$ID.codemeta.json"
        rm "$OUTPUTDIR/$ID.codemeta.json"
    fi
}

if [ $# -eq 0 ]; then
    #no configuration provided, just harvest only current project
    info "No configuration provided, harvesting current project"
    info "Attempting to guess source repo"
    SOURCEREPO=$(git remote get-url origin | sed -e "s|git@\(.*\):|https://\1/|")
    if [ -n "$SOURCEREPO" ]; then
        info "Source repo is $SOURCEREPO"
        [ -z "$IDENTIFIER" ] && IDENTIFIER=$(basename "$SOURCEREPO" | sed "s|.git||")
        CODEMETAPY_RECONCILE_ARGS="--identifier \"$IDENTIFIER\" --codeRepository \"$SOURCEREPO\""
    else
        [ -z "$IDENTIFIER" ] && IDENTIFIER="$(basename "$(pwd)")"
        CODEMETAPY_RECONCILE_ARGS="--identifier \"$IDENTIFIER\""
    fi
    if [ -n "$VALIDATE" ]; then
        CODEMETAPY_RECONCILE_ARGS="$CODEMETAPY_RECONCILE_ARGS --validate $VALIDATE"
    fi
    if harvest "$IDENTIFIER" "" "$CODEMETAPY_RECONCILE_ARGS"; then
        if [ ! -e "codemeta.json" ] || [ $REGEN -eq 1 ]; then
            mv "$OUTPUTDIR/$IDENTIFIER.codemeta.json" codemeta.json && info "Output renamed to $(pwd)/codemeta.json"
        fi
    fi
else
    #configuration files/directory provided, process them
    WORKDIR="$(pwd)"
    FOUND=0
    if [ -n "$VALIDATE" ]; then
        CODEMETAPY_RECONCILE_ARGS="$CODEMETAPY_RECONCILE_ARGS --validate $VALIDATE"
    fi
    for TARGET in "$@"; do
        if [ -f "$TARGET" ]; then
            process "$TARGET"
            FOUND=1
        elif [ -d "$TARGET" ]; then
            for SUBTARGET in "$TARGET"/*.yml; do
                if [ -e "$SUBTARGET" ]; then
                    process "$SUBTARGET"
                    FOUND=1
                fi
            done
        fi
    done
    [ $FOUND -eq 0 ] && die "No *.yml configuration files for the harvester. Just want to run without configuration on the current working directory? Then leave out the positional parameter"
fi
